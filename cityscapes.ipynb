{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# Agg backend runs without a display\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "from imgaug import augmenters as iaa\n",
    "# To find local version of the library\n",
    "ROOT_DIR = os.path.abspath('./')\n",
    "sys.path.append(ROOT_DIR)  \n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to trained weights file\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# Directory to save logs and model checkpoints, if not provided\n",
    "# through the command line argument --logs\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Results directory\n",
    "# Save submission files here\n",
    "RESULTS_DIR = os.path.join(ROOT_DIR, \"results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "class NucleusConfig(Config):\n",
    "    \"\"\"Configuration for training on the cityscapes dataset.\"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"cityscapes\"\n",
    "\n",
    "    # Adjust depending on your GPU memory\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Background + car + person +  \n",
    "    # tree + sidewalk + sky + terrain + building +\n",
    "    # vegetation + pole + traffic sign and many more\n",
    "    \n",
    "    # Number of classes (including background)\n",
    "    # restrict to background +  car, person, sky and sidewalk\n",
    "    NUM_CLASSES = 1 + 4\n",
    "\n",
    "    # Number of training and validation steps per epoch\n",
    "    STEPS_PER_EPOCH = 1000\n",
    "    VALIDATION_STEPS = 1000\n",
    "\n",
    "    # check if we need this\n",
    "    DETECTION_MIN_CONFIDENCE = 0\n",
    "\n",
    "    # Backbone network architecture\n",
    "    # Supported values are: resnet50, resnet101\n",
    "    BACKBONE = \"resnet50\"\n",
    "\n",
    "    # Input image resizing\n",
    "    # Random crops of size 512x512\n",
    "    IMAGE_RESIZE_MODE = \"crop\"\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    IMAGE_MIN_SCALE = 2.0\n",
    "\n",
    "    # Length of square anchor side in pixels\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
    "\n",
    "    # ROIs kept after non-maximum supression (training and inference)\n",
    "    POST_NMS_ROIS_TRAINING = 1000\n",
    "    POST_NMS_ROIS_INFERENCE = 2000\n",
    "\n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.9\n",
    "\n",
    "    # How many anchors per image to use for RPN training\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 64\n",
    "\n",
    "    # Image mean (RGB)\n",
    "    MEAN_PIXEL = np.array([43.53, 39.56, 48.22])\n",
    "\n",
    "    # If enabled, resizes instance masks to a smaller size to reduce\n",
    "    # memory load. Recommended when using high-resolution images.\n",
    "    USE_MINI_MASK = True\n",
    "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
    "\n",
    "    # Number of ROIs per image to feed to classifier/mask heads\n",
    "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
    "    # enough positive proposals to fill this and keep a positive:negative\n",
    "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
    "    # the RPN NMS threshold.\n",
    "    TRAIN_ROIS_PER_IMAGE = 128\n",
    "\n",
    "    # Maximum number of ground truth instances to use in one image\n",
    "    MAX_GT_INSTANCES = 200\n",
    "\n",
    "    # Max number of final detections per image\n",
    "    DETECTION_MAX_INSTANCES = 400\n",
    "\n",
    "\n",
    "class NucleusInferenceConfig(NucleusConfig):\n",
    "    # Set batch size to 1 to run one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    # Don't resize imager for inferencing\n",
    "    IMAGE_RESIZE_MODE = \"pad64\"\n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.7\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
